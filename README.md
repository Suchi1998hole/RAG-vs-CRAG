<<<<<<< HEAD
# ðŸ§  RAG vs CRAG Benchmark: Cached Retrieval-Augmented Generation using Weaviate + OpenAI

This project compares **Retrieval-Augmented Generation (RAG)** with **Cached Retrieval-Augmented Generation (CRAG)** by measuring **latency, computational load, and token usage** during text-generation tasks.  
It demonstrates how caching previously retrieved or generated results significantly improves efficiency without compromising accuracy.

---

## ðŸ“š Overview

| Model | Description |
|--------|-------------|
| **RAG (Retrieval-Augmented Generation)** | Retrieves relevant documents from a vector database (Weaviate) and feeds them into an OpenAI LLM to generate answers. |
| **CRAG (Cached Retrieval-Augmented Generation)** | Enhances RAG by introducing a cache layer (Redis) that stores query embeddings and generated responses. Subsequent similar queries are served instantly from cache. |

---

## ðŸ§© Architecture

=======
# ðŸ§  RAG vs CRAG Benchmark: Cached Retrieval-Augmented Generation using Weaviate + OpenAI

This project compares **Retrieval-Augmented Generation (RAG)** with **Cached Retrieval-Augmented Generation (CRAG)** by measuring **latency, computational load, and token usage** during text-generation tasks.  
It demonstrates how caching previously retrieved or generated results significantly improves efficiency without compromising accuracy.

---

## ðŸ“š Overview

| Model | Description |
|--------|-------------|
| **RAG (Retrieval-Augmented Generation)** | Retrieves relevant documents from a vector database (Weaviate) and feeds them into an OpenAI LLM to generate answers. |
| **CRAG (Cached Retrieval-Augmented Generation)** | Enhances RAG by introducing a cache layer (Redis) that stores query embeddings and generated responses. Subsequent similar queries are served instantly from cache. |

---

## ðŸ§© Architecture

>>>>>>> 24f43052dd6dc766f82a72a2fa2cc000adce2cc6
